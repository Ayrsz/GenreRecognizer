{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayrsz/SignalAndSistemyProject/blob/main/FeatureExtract.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fz7_fnJ4KaUM"
      },
      "outputs": [],
      "source": [
        "#Scientific computation\n",
        "import numpy as np\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "#Plot and view\n",
        "from matplotlib import pyplot as plt\n",
        "import IPython as ipy\n",
        "from IPython import display\n",
        "from IPython.display import Audio\n",
        "\n",
        "#Data manipulation\n",
        "import os\n",
        "import gc\n",
        "\n",
        "#Audio manipulation\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import cv2 as cv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UUiH7ivKloZ",
        "outputId": "2985cc11-7c2a-4f17-b6e5-89f5dc88ce55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No module named 'google.colab'\n",
            "Rodando localmente\n"
          ]
        }
      ],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/drive\", force_remount=True)\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    print(\"Rodando localmente\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNM1AUKsS6S-",
        "outputId": "3737b79c-c5ad-45a8-df8a-802ccadb65c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arquivo já unzipado, sem necessidade de ações.\n"
          ]
        }
      ],
      "source": [
        "# Unzip in a specific folder\n",
        "path_root = \"/home/mas11/Documents/Datasets\"\n",
        "path_zip = path_root + \"/GTZAN.zip\"\n",
        "with ZipFile(path_zip, \"r\") as zip_archive:\n",
        "    if not os.path.exists(path_root + \"/Data\"):\n",
        "        print(f\"Unzipando em : {path_root}\")\n",
        "        zip_archive.extractall(path_root)\n",
        "        print(\"Unzipado!\")\n",
        "    else:\n",
        "        print(\"Arquivo já unzipado, sem necessidade de ações.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7VFu6mTKS9IZ"
      },
      "outputs": [],
      "source": [
        "def dir_genres(path_all_genres : str) -> list[str]:\n",
        "    return [path_all_genres + '/' + pasta for pasta in os.listdir(path_all_genres)]\n",
        "\n",
        "#Return all files.wav separated per genres\n",
        "def dir_files_wav(path_genre : str) -> list[str]:\n",
        "  return [path_genre + '/' + arquivo for arquivo in os.listdir(path_genre)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6mDQJjbKybo"
      },
      "source": [
        "## Generate Escpectogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUVnyySbK_kJ",
        "outputId": "e68a033b-92ef-4a57-9a42-53f60e32861b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing on: /home/mas11/Documents/Datasets/Data/images/classical\n",
            "Carregando imagens, classical : 50.00%\n",
            "Carregando imagens, classical : 100.00%\n",
            "Writing on: /home/mas11/Documents/Datasets/Data/images/country\n",
            "Carregando imagens, country : 50.00%\n",
            "Carregando imagens, country : 100.00%\n",
            "Writing on: /home/mas11/Documents/Datasets/Data/images/metal\n",
            "Carregando imagens, metal : 50.00%\n",
            "Carregando imagens, metal : 100.00%\n",
            "Writing on: /home/mas11/Documents/Datasets/Data/images/jazz\n",
            "Carregando imagens, jazz : 49.49%\n",
            "Carregando imagens, jazz : 100.00%\n",
            "Writing on: /home/mas11/Documents/Datasets/Data/images/hiphop\n",
            "Carregando imagens, hiphop : 50.00%\n",
            "Carregando imagens, hiphop : 100.00%\n",
            "Writing on: /home/mas11/Documents/Datasets/Data/images/blues\n",
            "Carregando imagens, blues : 50.00%\n",
            "Carregando imagens, blues : 100.00%\n",
            "Writing on: /home/mas11/Documents/Datasets/Data/images/rock\n",
            "Carregando imagens, rock : 50.00%\n",
            "Carregando imagens, rock : 100.00%\n",
            "Writing on: /home/mas11/Documents/Datasets/Data/images/pop\n",
            "Carregando imagens, pop : 50.00%\n",
            "Carregando imagens, pop : 100.00%\n",
            "Writing on: /home/mas11/Documents/Datasets/Data/images/reggae\n",
            "Carregando imagens, reggae : 50.00%\n",
            "Carregando imagens, reggae : 100.00%\n",
            "Writing on: /home/mas11/Documents/Datasets/Data/images/disco\n",
            "Carregando imagens, disco : 50.00%\n",
            "Carregando imagens, disco : 100.00%\n"
          ]
        }
      ],
      "source": [
        "def is_dir_empty(path : str) -> bool:\n",
        "    with os.scandir(path) as iterator:\n",
        "        for entry in iterator:\n",
        "            if entry.name == '.ipynb_checkpoints':\n",
        "                continue\n",
        "            return False  # Se encontrar qualquer outro arquivo/pasta, não está vazio\n",
        "        return True  # Se só havia .ipynb_checkpoints (ou nada), está vazio\n",
        "def spectro_feat(audio : jnp.ndarray, sample_rate : int) -> jnp.ndarray:\n",
        "\n",
        "    audio = jax.device_put(audio)\n",
        "    FFT_SIZE = 512\n",
        "    HOP_SIZE = 256\n",
        "\n",
        "    hamming = jnp.hamming(FFT_SIZE)\n",
        "    num_frames = (len(audio) - FFT_SIZE) // HOP_SIZE + 1\n",
        "\n",
        "    def compute_fft(i):\n",
        "        start = i * HOP_SIZE\n",
        "        signal = jax.lax.dynamic_slice(audio, (start,), (FFT_SIZE,))\n",
        "        signal = signal * hamming\n",
        "        return jnp.fft.rfft(signal, n = FFT_SIZE)\n",
        "\n",
        "\n",
        "    sfft = jax.vmap(compute_fft)(jnp.arange(num_frames))\n",
        "\n",
        "    ssft = jnp.abs(sfft)**2 #Spectro\n",
        "    dB_format =  20 * jnp.log10( (ssft+1e-10) / 1e-10) #Spectro\n",
        "    return dB_format.T\n",
        "\n",
        "def spectro_feat_batch(batch : jnp.ndarray, sample_rate : int) -> jnp.ndarray:\n",
        "    return jax.vmap(lambda audio: spectro_feat(audio, sample_rate))(batch)\n",
        "\n",
        "def plt_spectogram(batch : jnp.ndarray, sample_rate : int, y_axis_type= \"linear\"):\n",
        "  escala_Y = spectro_feat_batch(batch, sample_rate)\n",
        "  escala_Y = np.array(escala_Y)\n",
        "  #fig = plt.figure(figsize=(10,10))\n",
        "  #plt.subplot(3,3,1)\n",
        "  for (i,audio) in enumerate(escala_Y):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    librosa.display.specshow(audio, sr = sample_rate, x_axis = \"time\", y_axis = y_axis_type, )\n",
        "    plt.set_cmap(\"magma\")\n",
        "    plt.colorbar()\n",
        "\n",
        "\n",
        "def create_batch(files : list[str], size : int, genre : str, shape = 661794):\n",
        "    batch_size = min(size, len(files))\n",
        "    batch = jnp.zeros((batch_size, shape))  # Inicializa batch zerado\n",
        "\n",
        "    nums = []\n",
        "    new_files = []  # Lista para armazenar arquivos que foram processados corretamente\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        try:\n",
        "\n",
        "            audio, sample_rate = sf.read(files[i])  # Mantém o SR original\n",
        "\n",
        "            if len(audio) < shape:\n",
        "                # Preenche com zeros se o áudio for menor que o tamanho esperado\n",
        "                audio = jnp.pad(audio, (0, shape - len(audio)))\n",
        "            elif len(audio) > shape:\n",
        "                # Se for maior, corta\n",
        "                audio = audio[:shape]\n",
        "\n",
        "            batch = batch.at[i].set(audio)\n",
        "\n",
        "            num = files[i].split(\"/\")[-1].split(\".\")[-2]\n",
        "\n",
        "            nums.append(num)\n",
        "            new_files.append(files[i])  # Adiciona à lista de arquivos processados\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao processar {files[i]}: {e}\")\n",
        "\n",
        "    # Remove os arquivos processados da lista original\n",
        "    for file in new_files:\n",
        "        files.remove(file)\n",
        "    batch = jax.device_put(batch)\n",
        "    return batch, nums, sample_rate, files\n",
        "\n",
        "\n",
        "def write_spectrogram(audios : jnp.ndarray, sample_rate: int, paths_write : list[str]):\n",
        "  escala_Y = spectro_feat_batch(audios, sample_rate)\n",
        "\n",
        "  del audios\n",
        "  gc.collect()\n",
        "\n",
        "  escala_Y = np.array(escala_Y)\n",
        "\n",
        "  assert len(escala_Y) == len(paths_write)\n",
        "\n",
        "  for (spec, path_write) in zip(escala_Y, paths_write):\n",
        "    spec = 255*(spec - np.max(spec))/(np.max(spec) - np.min(spec))\n",
        "    spec = spec.astype(np.uint8)\n",
        "    spec = 255 - spec\n",
        "    img = cv.applyColorMap(spec, cv.COLORMAP_INFERNO)\n",
        "\n",
        "    img = cv.resize(img, dsize = (500, 500), interpolation=cv.INTER_AREA)\n",
        "    cv.imwrite(path_write, img)\n",
        "\n",
        "\n",
        "def write_spectrogram_from_genre(genre_path : str):\n",
        "    files = dir_files_wav(genre_path)\n",
        "    total_files_start = len(files)\n",
        "    paths = np.array(genre_path.split(\"/\"))\n",
        "    genre = paths[-1]\n",
        "    size_path = len(paths)\n",
        "    genre_images_path = '/'.join(paths[0:size_path-2]) + \"/images/\" + genre\n",
        "    batch_size = 3\n",
        "\n",
        "    print(f\"Writing on: {genre_images_path}\")\n",
        "\n",
        "    if is_dir_empty(genre_images_path):\n",
        "        while(len(files) != 0):\n",
        "            try:\n",
        "                audios, nums, sample_rate, files = create_batch(files, batch_size, genre)\n",
        "\n",
        "                paths_write = [genre_images_path + \"/\" + genre + \".\" + num + \".png\" for num in nums]\n",
        "                write_spectrogram(audios, sample_rate, paths_write)#, path_write)\n",
        "\n",
        "                if(len(files) % 100 == 0):\n",
        "                    print(f\"Carregando imagens, {genre} : {((total_files_start - len(files))/total_files_start)*100:.2f}%\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Erro {e}\")\n",
        "                print(f\"Erro em {files[0]}\")\n",
        "                \n",
        "\n",
        "    else:\n",
        "        print(f\"Diretorio com imagens, porfavor esvazie: {genre}\")\n",
        "\n",
        "#Writting new images spectogram\n",
        "def write_all_spectrograms(path_genres : str):\n",
        "  genres_path = dir_genres(path_genres)\n",
        "\n",
        "  for genre_path in genres_path:\n",
        "    write_spectrogram_from_genre(genre_path)\n",
        "    \n",
        "\n",
        "\n",
        "write_all_spectrograms(path_root + \"/Data/genres_original\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIHE1X-2K3UA"
      },
      "source": [
        "# Features on time domain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CudaDevice(id=0)]\n"
          ]
        }
      ],
      "source": [
        "print(jax.devices())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lodMBaUPpCZg"
      },
      "outputs": [],
      "source": [
        "audio_example, sr = librosa.load(path_root + \"/Data/genres_original/metal/metal.00041.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xD2GLz0QEi-u"
      },
      "outputs": [],
      "source": [
        "def round_float_decimal(number):\n",
        "    if not isinstance(number, np.ndarray):\n",
        "        return float(f\"{number:.4f}\")\n",
        "    else:\n",
        "        return np.array([float(f\"{d:.4f}\") for d in number])\n",
        "\n",
        "def get_statistics_feature(audio : np.typing.NDArray, name) -> dict:\n",
        "    mean = round_float_decimal(np.mean(audio))\n",
        "    std = round_float_decimal(np.std(audio))\n",
        "    max = round_float_decimal(np.max(audio))\n",
        "    min = round_float_decimal(np.min(audio))\n",
        "    quartis = round_float_decimal(np.quantile(audio, [0.25, 0.5, 0.75]))\n",
        "    return {name + \"_mean\": mean, name + \"_std\":std,  name + \"_max\": max, name + \"_min\": min, name + \"_25p\":quartis[0], name + \"_50p\": quartis[1],  name+ \"_75p\": quartis[2]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMDhTnANmLPE"
      },
      "source": [
        "## Low level features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkFMHBeYeQm1"
      },
      "source": [
        "### Energy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULT1hN6XK850",
        "outputId": "c83d2d27-f126-490f-da07-161fee0e5522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'rms_mean': 0.0968, 'rms_std': 0.0227, 'rms_max': 0.1687, 'rms_min': 0.0383, 'rms_25p': np.float64(0.0797), 'rms_50p': np.float64(0.0946), 'rms_75p': np.float64(0.1082)}\n"
          ]
        }
      ],
      "source": [
        "def get_rms(audio, FRAME_SIZE = 1024):\n",
        "    rms = librosa.feature.rms(y = audio, frame_length= FRAME_SIZE)\n",
        "    feats = get_statistics_feature(rms, \"rms\")\n",
        "    return feats\n",
        "rms = get_rms(audio_example)\n",
        "print(rms)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79prusHfeTXz"
      },
      "source": [
        "### Zero-Cross-Rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UplXF36YscQF"
      },
      "outputs": [],
      "source": [
        "def get_zero_cross_rate(audio, FRAME_SIZE = 1024):\n",
        "    zero_cross = librosa.feature.zero_crossing_rate(audio, frame_length= FRAME_SIZE)\n",
        "    feats = get_statistics_feature(zero_cross, \"zero_cross\")\n",
        "    return feats\n",
        "\n",
        "\n",
        "rate = get_zero_cross_rate(audio_example)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6niBMUKfERa"
      },
      "source": [
        "### Amplitude Envelope"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjDhuPbvilI0",
        "outputId": "ef7cf7e1-4ab4-4aaa-ff35-286c5f62a415"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_26595/100862541.py:17: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sr = librosa.load(\"/content/drive/MyDrive/Datasets/DatasetAudios/GTZAN/Data/genres_original/blues/blues.00001.wav\")\n",
            "/home/mas11/.local/lib/python3.10/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Datasets/DatasetAudios/GTZAN/Data/genres_original/blues/blues.00001.wav'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/librosa/core/audio.py:176\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/librosa/core/audio.py:209\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/soundfile.py:690\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    689\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[0;32m--> 690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/soundfile.py:1265\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1264\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[0;32m-> 1265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
            "\u001b[0;31mLibsndfileError\u001b[0m: Error opening '/content/drive/MyDrive/Datasets/DatasetAudios/GTZAN/Data/genres_original/blues/blues.00001.wav': System error.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 17\u001b[0m\n\u001b[1;32m     11\u001b[0m     feats \u001b[38;5;241m=\u001b[39m get_statistics_feature(AEm, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mamplitude_envelope\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m feats\n\u001b[0;32m---> 17\u001b[0m audio, sr \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/content/drive/MyDrive/Datasets/DatasetAudios/GTZAN/Data/genres_original/blues/blues.00001.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m rms_info \u001b[38;5;241m=\u001b[39m get_amplitude_envelope(audio_example, sr)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(rms_info)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/librosa/core/audio.py:184\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n\u001b[1;32m    181\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    183\u001b[0m     )\n\u001b[0;32m--> 184\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__audioread_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/librosa/util/decorators.py:63\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[1;32m     55\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mDeprecated as of librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mIt will be removed in librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/librosa/core/audio.py:240\u001b[0m, in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    237\u001b[0m     reader \u001b[38;5;241m=\u001b[39m path\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43maudioread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[1;32m    243\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m input_file\u001b[38;5;241m.\u001b[39msamplerate\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/audioread/__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m BackendClass \u001b[38;5;129;01min\u001b[39;00m backends:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBackendClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError:\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/audioread/rawread.py:59\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m aifc\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Datasets/DatasetAudios/GTZAN/Data/genres_original/blues/blues.00001.wav'"
          ]
        }
      ],
      "source": [
        "def get_amplitude_envelope(audio, sample_rate, frame_size = 1024):\n",
        "    AEm = []\n",
        "    number_of_frames = len(audio) // frame_size\n",
        "    for i in range(number_of_frames):\n",
        "        start = i * frame_size\n",
        "        stop = start + frame_size\n",
        "        max_amp = np.max(audio[start:stop])\n",
        "        AEm.append(max_amp)\n",
        "    AEm = np.array(AEm)\n",
        "\n",
        "    feats = get_statistics_feature(AEm, \"amplitude_envelope\")\n",
        "    return feats\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "audio, sr = librosa.load(\"/content/drive/MyDrive/Datasets/DatasetAudios/GTZAN/Data/genres_original/blues/blues.00001.wav\")\n",
        "rms_info = get_amplitude_envelope(audio_example, sr)\n",
        "print(rms_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfPfJpOBnGSQ"
      },
      "source": [
        "## Medium level Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMZ-PQjVqpSK"
      },
      "source": [
        "### Kurtosis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yttKemqxqrk7",
        "outputId": "67e916a2-f3ba-460d-9454-e031e9a0e7e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8641\n"
          ]
        }
      ],
      "source": [
        "#Analise do formato da curva da distribuição dos valores do sinal\n",
        "# Kurtosis -> O quão intenso é o pico em comparação ao resto\n",
        "# K = E([SINAL - MEDIA]^4)/DESVIO_PADRÃO ^4\n",
        "# K < 3 -> Mais suave que uma distribuição gaussiana\n",
        "# K = 3 -> Parecido com uma distribuição gaussiana\n",
        "# K > 3 -> Mais \"pontudo\" que a distribuicação gaussiana\n",
        "def get_kurtosis(audio):\n",
        "    audio_normalizado = (audio - np.mean(audio))/np.max(audio)\n",
        "\n",
        "    mean = np.mean(audio_normalizado)\n",
        "    std = np.std(audio_normalizado)\n",
        "    dif_audio_media = audio - mean\n",
        "\n",
        "    valor_esperado = np.mean(dif_audio_media**4)\n",
        "\n",
        "    kurtosis = np.float64(valor_esperado/std**4)\n",
        "    return round_float_decimal(kurtosis)\n",
        "\n",
        "print(get_kurtosis(audio_example))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvVBIuKjnBOI"
      },
      "source": [
        "## High level features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1_w9d5HnKUI"
      },
      "source": [
        "### Tempo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWDhN7ovnJ7Z",
        "outputId": "3b0336c9-adb5-42d8-a95e-c7785378e93c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[117]\n"
          ]
        }
      ],
      "source": [
        "def get_tempo(audio, sample_rate):\n",
        "    tempo, beats = librosa.beat.beat_track(y = audio, sr = sample_rate)\n",
        "    tempo = tempo #É um vetor de apenas um unico valor\n",
        "    return np.int32(tempo)\n",
        "\n",
        "\n",
        "print(get_tempo(audio_example, sr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyHTUG4ZK9n6"
      },
      "source": [
        "# Features on frequency domain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9nT9KJ16msF"
      },
      "source": [
        "### Low level feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3E5JHv66mZO",
        "outputId": "d36de110-9da7-450c-89a2-2db6372c0710"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'spectral_centroid_mean': 2269.1619, 'spectral_centroid_std': 368.4678, 'spectral_centroid_max': 3496.8095, 'spectral_centroid_min': 1306.5515, 'spectral_centroid_25p': np.float64(2005.6192), 'spectral_centroid_50p': np.float64(2233.7791), 'spectral_centroid_75p': np.float64(2532.513)}\n"
          ]
        }
      ],
      "source": [
        "#Gera um \"centro de massa\"\n",
        "#Média das frequencias, ponderadas pela amplitude daquela sample para cada frame (usa sft)\n",
        "def get_spectral_centroid(audio, sample_rate):\n",
        "    spectral_centroid = librosa.feature.spectral_centroid(y = audio, sr = sample_rate)\n",
        "    feats = get_statistics_feature(spectral_centroid, \"spectral_centroid\")\n",
        "    return feats\n",
        "\n",
        "centroid = get_spectral_centroid(audio_example, sr)\n",
        "print(centroid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57gmTB1r8RrJ"
      },
      "source": [
        "### High level feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eir8oQ-M8RJX",
        "outputId": "4173b124-42d9-450c-beaf-af6469460e3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'mfcc#00_mean': -100.4234, 'mfcc#00_std': 36.4089, 'mfcc#01_mean': 104.6932, 'mfcc#01_std': 19.8516, 'mfcc#02_mean': -57.254, 'mfcc#02_std': 18.1442, 'mfcc#03_mean': 56.5769, 'mfcc#03_std': 10.628, 'mfcc#04_mean': -5.5556, 'mfcc#04_std': 9.6729, 'mfcc#05_mean': 22.8333, 'mfcc#05_std': 10.0632, 'mfcc#06_mean': -6.1715, 'mfcc#06_std': 10.5025, 'mfcc#07_mean': 23.0971, 'mfcc#07_std': 8.8752, 'mfcc#08_mean': -19.072, 'mfcc#08_std': 7.0803, 'mfcc#09_mean': 17.7954, 'mfcc#09_std': 7.2162, 'mfcc#10_mean': -13.783, 'mfcc#10_std': 6.9338, 'mfcc#11_mean': 9.9628, 'mfcc#11_std': 7.0728, 'mfcc#12_mean': -14.8587, 'mfcc#12_std': 6.9912}\n"
          ]
        }
      ],
      "source": [
        "def get_mel_coef(audio, sample_rate):\n",
        "    mfcc = librosa.feature.mfcc(y = audio, sr = sample_rate, n_mfcc = 13)\n",
        "    coefs_estatistics = {}\n",
        "    for (i,coefs) in enumerate(mfcc):\n",
        "        coefs_estatistics[\"mfcc#\" + f\"{i:02d}_mean\"] = round_float_decimal(np.mean(coefs))\n",
        "        coefs_estatistics[\"mfcc#\" + f\"{i:02d}_std\"] = round_float_decimal(np.std(coefs))\n",
        "\n",
        "\n",
        "    return coefs_estatistics\n",
        "\n",
        "mfcc = get_mel_coef(audio_example, sr)\n",
        "print(mfcc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWHxnz2v-X_n"
      },
      "source": [
        "# Create CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOX7Yd1x-aXH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acessing:  /home/mas11/Documents/Datasets/Data/genres_original/classical\n",
            "Acessing:  /home/mas11/Documents/Datasets/Data/genres_original/country\n",
            "Acessing:  /home/mas11/Documents/Datasets/Data/genres_original/metal\n",
            "Acessing:  /home/mas11/Documents/Datasets/Data/genres_original/jazz\n",
            "Acessing:  /home/mas11/Documents/Datasets/Data/genres_original/hiphop\n",
            "Acessing:  /home/mas11/Documents/Datasets/Data/genres_original/blues\n",
            "Acessing:  /home/mas11/Documents/Datasets/Data/genres_original/rock\n",
            "Acessing:  /home/mas11/Documents/Datasets/Data/genres_original/pop\n",
            "Acessing:  /home/mas11/Documents/Datasets/Data/genres_original/reggae\n",
            "Acessing:  /home/mas11/Documents/Datasets/Data/genres_original/disco\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "\n",
        "\n",
        "def get_features_dict(audio, sample_rate, name, dir_image):\n",
        "    features_dict = {\"name\": name + \".wav\", \"dir_image\": dir_image}\n",
        "\n",
        "    rms = (get_rms(audio, sample_rate))\n",
        "    zero_cross = (get_zero_cross_rate(audio))\n",
        "    amplitude_env = (get_amplitude_envelope(audio, sample_rate))\n",
        "    spectral_centroid = (get_spectral_centroid(audio, sample_rate))\n",
        "    mfcc_coef = (get_mel_coef(audio, sample_rate))\n",
        "\n",
        "    features_dict = features_dict | rms | zero_cross | amplitude_env | spectral_centroid | mfcc_coef\n",
        "\n",
        "    kurtosis = get_kurtosis(audio)\n",
        "    tempo = get_tempo(audio, sample_rate)\n",
        "    label = name.split(\".\")[0]\n",
        "\n",
        "    features_dict.update({\"tempo\":tempo, \"kurtosis\":kurtosis, \"label\":label})\n",
        "\n",
        "    return features_dict\n",
        "\n",
        "\n",
        "\n",
        "def write_csv_genre(genre_path, path_write):\n",
        "    files = dir_files_wav(genre_path)\n",
        "    features_vector = []\n",
        "\n",
        "   \n",
        "\n",
        "    for (i, file) in enumerate(files):\n",
        "        path = file.split(\"/\")\n",
        "        name = path[-1].replace(\".wav\", \"\")\n",
        "        genre = name.split(\".\")[0]\n",
        "        idx_data = [i for i in range(len(path)) if path[i] == \"Data\" ][0]\n",
        "        dir_image = \"/\".join(path[:idx_data]) + \"/Data/images/\" + genre + \"/\" + name + \".png\"\n",
        "        audio, sample_rate = librosa.load(file)\n",
        "        features_dict = get_features_dict(audio, sample_rate, name, dir_image)\n",
        "        features_vector.append(features_dict)\n",
        "            \n",
        "    return features_vector\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "def write_csv(root_dir, path_write):\n",
        "    genres_dir = dir_genres(root_dir)\n",
        "    columns = ['name', 'dir_image', 'rms_mean', 'rms_std', 'rms_max', 'rms_min', 'rms_25p', 'rms_50p', 'rms_75p', \n",
        "               'zero_cross_mean', 'zero_cross_std', 'zero_cross_max', 'zero_cross_min', 'zero_cross_25p', 'zero_cross_50p', 'zero_cross_75p', \n",
        "               'amplitude_envelope_mean', 'amplitude_envelope_std', 'amplitude_envelope_max', 'amplitude_envelope_min', 'amplitude_envelope_25p',\n",
        "               'amplitude_envelope_50p', 'amplitude_envelope_75p', 'spectral_centroid_mean', 'spectral_centroid_std', 'spectral_centroid_max', \n",
        "               'spectral_centroid_min', 'spectral_centroid_25p', 'spectral_centroid_50p', 'spectral_centroid_75p', 'mfcc#00_mean', 'mfcc#00_std', \n",
        "               'mfcc#01_mean', 'mfcc#01_std', 'mfcc#02_mean', 'mfcc#02_std', 'mfcc#03_mean', 'mfcc#03_std', 'mfcc#04_mean', 'mfcc#04_std', 'mfcc#05_mean', \n",
        "               'mfcc#05_std', 'mfcc#06_mean', 'mfcc#06_std', 'mfcc#07_mean', 'mfcc#07_std', 'mfcc#08_mean', 'mfcc#08_std', 'mfcc#09_mean', 'mfcc#09_std', \n",
        "               'mfcc#10_mean', 'mfcc#10_std', 'mfcc#11_mean', 'mfcc#11_std', 'mfcc#12_mean', 'mfcc#12_std', 'tempo', 'kurtosis', 'label']\n",
        "    \n",
        "    with open(path_write + \"/feats.csv\", \"w\") as f:\n",
        "        writer = csv.DictWriter(f, columns)\n",
        "        writer.writeheader()\n",
        "        for genre in genres_dir:\n",
        "            print(\"Acessing: \", genre)\n",
        "            lines = write_csv_genre(genre, path_write)\n",
        "            writer.writerows(lines)\n",
        "\n",
        "        f.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "write_csv(path_root + \"/Data/genres_original\",  path_root + \"/Data\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM/YGTCZZ3VebJ2oc2ftbUH",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
